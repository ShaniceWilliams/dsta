{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DSTA\n",
    "\n",
    "#### Non-binary Classification: the MNIST784 dataset\n",
    "\n",
    "A simple notebook for testing a classifier against the MNIST 784 dataset.\n",
    "\n",
    "A solution is also available from the Scikit-learn web site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import check_random_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = 'mnist_784'\n",
    "\n",
    "\n",
    "mnist = fetch_openml(FILE, version=1)\n",
    "\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=mnist['data'], mnist['target']\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpi\n",
    "import matplotlib.pyplot as plt\n",
    "some_digit=X[0]\n",
    "some_digit_image=some_digit.reshape(28,28)\n",
    "plt.imshow(some_digit_image, cmap=\"binary\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data-set \n",
    "\n",
    "* Prepare the dataset by dividing it into train and test set.\n",
    "  \n",
    "* First 6000 is used as training and the rest as test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification\n",
    "\n",
    "* Scale $X$ to have zero mean and unit variance [required by regressor]\n",
    "* Fit the model.\n",
    "* Find the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "#scale data to have zero mean and unit variance [required by regressor]\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# apply logistic regressor with 'sag' solver, C is the inverse regularization strength\n",
    "clf = LogisticRegression(C=1e5,\n",
    "                         multi_class='multinomial',\n",
    "                         penalty='l2', solver='sag', tol=0.1)\n",
    "# fit data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# percentage of nonzero weights\n",
    "sparsity = np.mean(clf.coef_ == 0) * 100\n",
    "\n",
    "# compute accuracy\n",
    "score = clf.score(X_test, y_test)\n",
    "\n",
    "#display run time\n",
    "run_time = time.time() - t0\n",
    "\n",
    "print('Example run in %.3f s' % run_time)\n",
    "\n",
    "print(\"Sparsity with L2 penalty: %.2f%%\" % sparsity)\n",
    "print(\"Test score with L2 penalty: %.4f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#get prediction from the classifier\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "#print classification report\n",
    "print (classification_report(\n",
    "        y_test,\n",
    "        y_pred\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot weights vs the pixel position\n",
    "coef = clf.coef_.copy()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "scale = np.abs(coef).max()\n",
    "\n",
    "for i in range(10):\n",
    "    l2_plot = plt.subplot(2, 5, i + 1)\n",
    "    l2_plot.imshow(coef[i].reshape(28, 28), interpolation='nearest',\n",
    "                   cmap=plt.cm.Greys, vmin=-scale, vmax=scale)\n",
    "    l2_plot.set_xticks(())\n",
    "    l2_plot.set_yticks(())\n",
    "    l2_plot.set_xlabel('Class %i' % i)\n",
    "plt.suptitle('classification weights vector $w_j$ for digit class $j$')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
