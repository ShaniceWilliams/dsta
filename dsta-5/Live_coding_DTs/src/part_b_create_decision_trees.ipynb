{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae258780",
   "metadata": {
    "id": "ae258780"
   },
   "source": [
    "### DSTA Live coding experience\n",
    "\n",
    "#### Part B: Implementing Decision Trees from Python up\n",
    "\n",
    "__This notebook requires the dataset file 'mushroom.csv' also available from the repo__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "XJIfrPeS6vvW",
   "metadata": {
    "id": "XJIfrPeS6vvW"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The code will run on dataset file DATAFILE \n",
    "and print a barchart reporting the accuracy achieved by \n",
    "segmenting individual features (it runs 22 times).\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from math import log2\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "_XZ_2xo57Xlv",
   "metadata": {
    "id": "_XZ_2xo57Xlv"
   },
   "outputs": [],
   "source": [
    "# this can be changed to reflect the exact location of the dataset file\n",
    "DATAFILE = '../data/mushrooms.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0e39804",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "a0e39804",
    "outputId": "fcbdc764-bbc4-4bc2-9508-9c7627bc59d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
      "0     p         x           s         n       t    p               f   \n",
      "1     e         x           s         y       t    a               f   \n",
      "2     e         b           s         w       t    l               f   \n",
      "3     p         x           y         w       t    p               f   \n",
      "4     e         x           s         g       f    n               f   \n",
      "\n",
      "  gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
      "0            c         n          k  ...                        s   \n",
      "1            c         b          k  ...                        s   \n",
      "2            c         b          n  ...                        s   \n",
      "3            c         n          n  ...                        s   \n",
      "4            w         b          k  ...                        s   \n",
      "\n",
      "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
      "0                      w                      w         p          w   \n",
      "1                      w                      w         p          w   \n",
      "2                      w                      w         p          w   \n",
      "3                      w                      w         p          w   \n",
      "4                      w                      w         p          w   \n",
      "\n",
      "  ring-number ring-type spore-print-color population habitat  \n",
      "0           o         p                 k          s       u  \n",
      "1           o         p                 n          n       g  \n",
      "2           o         p                 n          n       m  \n",
      "3           o         p                 k          s       u  \n",
      "4           o         e                 n          a       g  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "['p' 'e']\n",
      "   class  cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
      "0      1          5            2          4        1     6                1   \n",
      "1      0          5            2          9        1     0                1   \n",
      "2      0          0            2          8        1     3                1   \n",
      "3      1          5            3          8        1     6                1   \n",
      "4      0          5            2          3        0     5                1   \n",
      "\n",
      "   gill-spacing  gill-size  gill-color  ...  stalk-surface-below-ring  \\\n",
      "0             0          1           4  ...                         2   \n",
      "1             0          0           4  ...                         2   \n",
      "2             0          0           5  ...                         2   \n",
      "3             0          1           5  ...                         2   \n",
      "4             1          0           4  ...                         2   \n",
      "\n",
      "   stalk-color-above-ring  stalk-color-below-ring  veil-type  veil-color  \\\n",
      "0                       7                       7          0           2   \n",
      "1                       7                       7          0           2   \n",
      "2                       7                       7          0           2   \n",
      "3                       7                       7          0           2   \n",
      "4                       7                       7          0           2   \n",
      "\n",
      "   ring-number  ring-type  spore-print-color  population  habitat  \n",
      "0            1          4                  2           3        5  \n",
      "1            1          4                  3           2        1  \n",
      "2            1          4                  3           2        3  \n",
      "3            1          4                  2           3        5  \n",
      "4            1          0                  3           0        1  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "Accuracy using only cap-shape feature is: 0.6937\n",
      "['class', 'cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor', 'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring', 'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number', 'ring-type', 'spore-print-color', 'population', 'habitat']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "class DecisionTree(object):\n",
    "    \"\"\"\n",
    "       DecisionTree Class implements ID3 and CART.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, criterion='entropy'):\n",
    "        \"\"\"\n",
    "           Decision Tree constructor.\n",
    "        Parameters\n",
    "        ----------\n",
    "        criterion : str\n",
    "            The criterion is set by default to 'entropy'. \n",
    "            Possible values are 'entropy' and 'gini'. \n",
    "            The criterion is used when we calculate the\n",
    "            Gain on each feature selection.\n",
    "        \"\"\"\n",
    "\n",
    "        self.tree = None  # default model tree\n",
    "\n",
    "        self.features = None  # default features array\n",
    "\n",
    "        self.target = None  # default model target\n",
    "\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series, features: []):\n",
    "        \"\"\"\n",
    "           Short summary.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd.DataFrame\n",
    "            Predictors pandas DataFrame.\n",
    "        y : pd.Series\n",
    "            Target true values DataSerie.\n",
    "        features : []\n",
    "            Array of `features` to use in model.\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            Dictionary object containing the tree representation.\n",
    "        \"\"\"\n",
    "        data = pd.concat([X, y], axis=1)\n",
    "        self.features = features\n",
    "        self.target = y.name\n",
    "        self.tree = self.build_tree(data, features)\n",
    "\n",
    "        return self.tree\n",
    "\n",
    "    def predict(self, X: pd.DataFrame):\n",
    "        \"\"\"\n",
    "           Predict the target based on X features.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd.DataFrame\n",
    "            Predictors pandas DataFrame.\n",
    "        Returns\n",
    "        -------\n",
    "        pd.Serie\n",
    "            DataSerie corresponding to the actual predictions.\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        for index, datapoint in X.iterrows():\n",
    "            results.append(self.classify(self.tree, datapoint))\n",
    "\n",
    "        return pd.Series(results, index=X.index, dtype='int', name=self.target)\n",
    "\n",
    "    def accuracy(self, y_true: pd.Series, y_predicted: pd.Series):\n",
    "        \"\"\"\n",
    "           Calculate the accuracy of the decision tree.\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_true : pd.Series\n",
    "            The target true values.\n",
    "        y_predicted : pd.Series\n",
    "            The target predicted values.\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            The actual DT accuracy rounded to 4 decimals.\n",
    "        \"\"\"\n",
    "        y_check = y_true == y_predicted\n",
    "\n",
    "        return round(y_check.sum() / len(y_check), 4)\n",
    "\n",
    "    def classify(self, tree, datapoint):\n",
    "        \"\"\"\n",
    "           Classify a specific data entry.\n",
    "        Parameters\n",
    "        ----------\n",
    "        tree : {}\n",
    "            Dictionary object containing the tree representation.\n",
    "        datapoint : object\n",
    "            datapoint containing the features.\n",
    "        Returns\n",
    "        -------\n",
    "        type\n",
    "            Corresponding class predicted associated to datapoint.\n",
    "        \"\"\"\n",
    "        if type(tree) == dict:\n",
    "            first_feature = list(tree.keys())[0]\n",
    "\n",
    "            try:\n",
    "                subtree = tree[first_feature][datapoint[first_feature]]\n",
    "                return self.classify(subtree, datapoint)\n",
    "            except Exception:\n",
    "                return False\n",
    "        else:\n",
    "            return tree\n",
    "\n",
    "    def calc_entropy(self, p):\n",
    "        \"\"\"\n",
    "           Calculate the entropy for a specific feature.\n",
    "        Parameters\n",
    "        ----------\n",
    "        p : type\n",
    "            Description of parameter `p`.\n",
    "        Returns\n",
    "        -------\n",
    "        type\n",
    "            Description of returned object.\n",
    "        \"\"\"\n",
    "        if p != 0:\n",
    "            return -p * log2(p)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def calc_info_gain(self, data: pd.DataFrame, feature: str):\n",
    "        \"\"\"\n",
    "           Calculate the entropy gain in ID3 for a specific feature.\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : pd.DataFrame\n",
    "            Data used to calculate the entropy gain.\n",
    "        feature : str\n",
    "            The feature name.\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            The corresping entropy gain for the specified feature.\n",
    "        \"\"\"\n",
    "\n",
    "        gain = 0\n",
    "        data_len = len(data)\n",
    "        feature_values = {}\n",
    "        classes = {}\n",
    "\n",
    "        # Loop and get distinct feature value.\n",
    "        for index, datapoint in data.iterrows():\n",
    "            #get the individual data feature and its target.\n",
    "            #For example: 'cap-shape' value and the class\n",
    "            \"\"\"\n",
    "            For example for cap-shape feature we will get counts\n",
    "            cap-shape\n",
    "            {\n",
    "             0: {'count': 398, 'classes': {0: 355, 1: 43}},\n",
    "             1: {'count': 4, 'classes': {1: 4}},\n",
    "             2: {'count': 2807, 'classes': {1: 1388, 0: 1419}},\n",
    "             3: {'count': 771, 'classes': {1: 556, 0: 215}},\n",
    "             4: {'count': 29, 'classes': {0: 29}},\n",
    "             5: {'count': 3302, 'classes': {1: 1545, 0: 1757}}\n",
    "            }\n",
    "            \"\"\"\n",
    "            data_cls = datapoint[self.target]\n",
    "            data_ft = datapoint[feature]\n",
    "        \n",
    "            if data_ft in feature_values.keys():\n",
    "                feature_values[data_ft]['count'] += 1\n",
    "        \n",
    "                if data_cls in feature_values[data_ft]['classes'].keys():\n",
    "                    feature_values[data_ft]['classes'][data_cls] += 1\n",
    "                else:\n",
    "                    feature_values[data_ft]['classes'][data_cls] = 1\n",
    "            else:\n",
    "                feature_values[data_ft] = {}\n",
    "                feature_values[data_ft]['count'] = 1\n",
    "                feature_values[data_ft]['classes'] = {}\n",
    "                feature_values[data_ft]['classes'][data_cls] = 1\n",
    "        \n",
    "            # Count classes for this feature\n",
    "            if data_cls in classes.keys():\n",
    "                classes[data_cls] += 1\n",
    "            else:\n",
    "                classes[data_cls] = 1\n",
    "        \n",
    "        #print(feature)\n",
    "        #print(feature_values)\n",
    "        #print(classes)\n",
    "         # Loop through all possible feature values and calculate corresponding\n",
    "        # feature_value / class map.\n",
    "        feat_entropy_sum = 0\n",
    "        \n",
    "        for feature_val, feature_stats in feature_values.items():\n",
    "            feat_entropy = 0\n",
    "        \n",
    "            for feat_class, feat_count in feature_stats['classes'].items():\n",
    "                feature_prob = feat_count / feature_stats['count']\n",
    "                feat_entropy += self.calc_entropy(feature_prob)\n",
    "        \n",
    "            feat_entropy_sum += (feature_stats['count']/data_len)*feat_entropy\n",
    "\n",
    "        # Calculate Entropy\n",
    "        entropy = 0\n",
    "        #print(\"*****************************************\")\n",
    "        #print(classes)\n",
    "        #print(\"*****************************************\")\n",
    "        for class_name, class_count in classes.items():\n",
    "            class_prob = class_count / data_len\n",
    "            entropy += self.calc_entropy(class_prob)\n",
    "\n",
    "        # Calc gain based on ID3 formulae\n",
    "        gain = entropy - feat_entropy_sum\n",
    "        #print(\"Entropy of classes\", entropy)\n",
    "        #print(feat_entropy_sum)\n",
    "        #print(gain)\n",
    "        return gain\n",
    "\n",
    "    def build_tree(self, data: pd.DataFrame, features: []):\n",
    "        \"\"\"\n",
    "           Build the DecisionTree representation.\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : pd.DataFrame\n",
    "            Data used to build Decision Tree model.\n",
    "        features : []\n",
    "            Array of `features` to use in model.\n",
    "        Returns\n",
    "        -------\n",
    "        {}\n",
    "            Dictionary object containing the tree representation.\n",
    "        \"\"\"\n",
    "\n",
    "        gains = []\n",
    "\n",
    "        tree = {}\n",
    "\n",
    "        # calculate default classe based on the most present class\n",
    "        default = data[self.target].value_counts(sort=True).index[0]\n",
    "\n",
    "        # Doing this as to prevent features alteration.\n",
    "        copy_features = features.copy()\n",
    "\n",
    "        if copy_features:\n",
    "            for feature in copy_features:\n",
    "                gains.append(self.calc_info_gain(data, feature))\n",
    "            ft_gains = list(zip(features, gains))\n",
    "\n",
    "            max = sorted(ft_gains, key=lambda x: x[1], reverse=True)[0]\n",
    "            best_feature = max[0]\n",
    "            best_feature_values = data[best_feature].unique()\n",
    "\n",
    "            # Remove best feature from features list\n",
    "            copy_features.remove(max[0])\n",
    "\n",
    "            for best_feature_value in best_feature_values:\n",
    "                feature_data = data[data[best_feature] == best_feature_value]\n",
    "                # print(best_feature_value)\n",
    "                subtree = self.build_tree(feature_data, copy_features)\n",
    "                if best_feature in tree.keys():\n",
    "                    tree[best_feature][best_feature_value] = subtree\n",
    "                else:\n",
    "                    tree[best_feature] = {}\n",
    "                    tree[best_feature][best_feature_value] = subtree\n",
    "            return tree\n",
    "        else:\n",
    "            return default\n",
    "    \n",
    "    def print_tree(self, tree: {}, prefix=''):\n",
    "        \"\"\"Print tree object representation.\n",
    "        Parameters\n",
    "        ----------\n",
    "        tree : {}\n",
    "            The tree dict to print.\n",
    "        prefix : str\n",
    "            Line prefix.\n",
    "        Returns\n",
    "        -------\n",
    "        type\n",
    "            Description of returned object.\n",
    "        \"\"\"\n",
    "        if type(tree) == dict:\n",
    "            for key in tree.keys():\n",
    "                print(prefix, key)\n",
    "                for item in tree[key].keys():\n",
    "                    print(prefix, item)\n",
    "                    self.print_tree(tree[key][item], prefix + \"\\t\")\n",
    "    \n",
    "        else:\n",
    "            print(prefix, \"\\t->\\t\", tree)\n",
    "\n",
    "def bar_plot_feature_accuracies( X_train, y_train, X_test, y_test, features):\n",
    "    \"\"\"Plot accuracies for each feature\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train, y_train, X_test, y_test: Dataframe\n",
    "        Train and test data\n",
    "    features: list\n",
    "        A list of features to be experimented with\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    dtree=DecisionTree()\n",
    "    acuracies=[]\n",
    "    print(features)\n",
    "    for ft in features:\n",
    "        if ft=='class':\n",
    "            continue\n",
    "        else:\n",
    "            fts=[ft]\n",
    "            clf=dtree.fit(X_train,y_train,fts)\n",
    "            y_pred=dtree.predict(X_test)\n",
    "            acuracies.append(dtree.accuracy(y_test, y_pred))\n",
    "    \n",
    "    data = np.array(acuracies)\n",
    "    x = np.arange(len(acuracies))\n",
    "    width = 0.2  # width of bar\n",
    "    sns.axes_style('white')\n",
    "    sns.set_style('white')\n",
    "    ax = sns.barplot(x=x, y=data)\n",
    "    ax.set(xlabel='Feature number', ylabel='Accuracy')\n",
    "    plt.show()\n",
    "\n",
    "def main(ifname):\n",
    "    \"\"\"Load decision tree model and model's perform accuracy test\n",
    "    Parameters\n",
    "    ----------\n",
    "    ifname: str\n",
    "        The data file name\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    #Load dataset using pandas\n",
    "    df = pd.read_csv(ifname)\n",
    "    \n",
    "    #check the first few rows in the dataset\n",
    "    print(df.head())\n",
    "    \n",
    "    #Check usnique classes of the dataset\n",
    "    print(df['class'].unique())\n",
    "    #Use labelencoder to covert categries of features into ordianl value_counts\n",
    "    \n",
    "    labelencoder=LabelEncoder()\n",
    "    \n",
    "    for column in df.columns:\n",
    "        df[column] = labelencoder.fit_transform(df[column])\n",
    "    \n",
    "    #Check columns after converting to ordinal values\n",
    "    print(df.head())\n",
    "    \n",
    "    #get the features into X by dropping the target class\n",
    "    X = df.drop(['class'], axis=1)\n",
    "    \n",
    "    #Take the target classes from datafram into y\n",
    "    y = df['class']\n",
    "    \n",
    "    #Split dataset into train and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.1)\n",
    "    \n",
    "    #Call Decision Tree\n",
    "    dtree=DecisionTree()\n",
    "    \n",
    "    #Get the feature columns into a list that we want to use\n",
    "    #You can add more columns here\n",
    "    features=['cap-shape', 'cap-surface', 'cap-color']\n",
    "    \n",
    "    #Train the model\n",
    "    clf=dtree.fit(X_train,y_train,features)\n",
    "    #Print the tree if you want\n",
    "    #tree.print_tree(tree.tree)\n",
    "    #Get the predictions\n",
    "    \n",
    "    y_pred=dtree.predict(X_test)\n",
    "    print(\"Accuracy using only cap-shape feature is:\", dtree.accuracy(y_test, y_pred))\n",
    "    features=list(df)\n",
    "    \n",
    "    #Plot feature by feature accuracies\n",
    "    bar_plot_feature_accuracies( X_train, y_train, X_test, y_test,features)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # this allows you to pass the file name as the first argument when you call\n",
    "    # your script from the command line\n",
    "    # so to run this script use:\n",
    "    main(DATAFILE)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}