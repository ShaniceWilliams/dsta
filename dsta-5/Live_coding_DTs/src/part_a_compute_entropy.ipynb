{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "17effc2e",
      "metadata": {
        "id": "17effc2e"
      },
      "source": [
        "### DSTA Live coding experience\n",
        "\n",
        "#### Part A: Computing the Shannon's Information Entropy of a distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e32db181",
      "metadata": {
        "id": "e32db181"
      },
      "source": [
        "#### Task: define a function that takes data, in the form of a probability distribution, and computes its information entropy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YoK5YyDrBBer",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YoK5YyDrBBer"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69c38a91",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "69c38a91"
      },
      "outputs": [],
      "source": [
        "def H(distribution):\n",
        "    '''computes Shannon's entropy of a distribution: a numpy array/list'''\n",
        "\n",
        "    entropy=0.0\n",
        "    for dist in distribution:\n",
        "        if dist==0.0:\n",
        "            entropy+=0\n",
        "        else:\n",
        "            entropy+= dist* math.log(dist, 2)\n",
        "    return -entropy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7eeae85",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7eeae85",
        "outputId": "1bca5f67-6f89-4f91-d4cb-fe8cb3053583"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entropy of London is: 3.125\n"
          ]
        }
      ],
      "source": [
        "snow=1/16\n",
        "showers=1/8\n",
        "light_rain=1/8\n",
        "wet=1/8\n",
        "misty=1/8\n",
        "cloudy=1/8\n",
        "breezy=1/8\n",
        "bright=1/8\n",
        "sunny=1/16\n",
        "\n",
        "X_LDN=[snow, showers, light_rain, wet, misty, cloudy, breezy, bright,sunny]\n",
        "\n",
        "print(\"Entropy of London is:\", H(X_LDN))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80fabf7e",
      "metadata": {
        "id": "80fabf7e"
      },
      "source": [
        "### Example: The UCI Mushroom dataset\n",
        "\n",
        "* Mushroom dataset can be found: in https://archive.ics.uci.edu/ml/datasets/mushroom\n",
        "* Each mushroom type is describe by 12 (mostly morphological) features.\n",
        "* Binary classification: edible or poisonous? (misclassification could be catastrophic here).\n",
        "* Write a function that will calculate the information entropy of a give class of possible mushroom types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fedd555",
      "metadata": {
        "id": "3fedd555"
      },
      "outputs": [],
      "source": [
        "def calculate_class_entropy(data):\n",
        "    #create a frequency dictionary of classes\n",
        "    classes={}\n",
        "    data_len=len(data)\n",
        "\n",
        "    print(\"Data Length: \", data_len)\n",
        "\n",
        "    for index, datapoint in data.iterrows():\n",
        "        #print(index,datapoint['class'])\n",
        "        if datapoint['class'] in classes:\n",
        "            classes[datapoint['class']]+=1\n",
        "        else:\n",
        "            classes[datapoint['class']]=1\n",
        "            \n",
        "    print(classes)\n",
        "    #calculate probablity distribution for classes\n",
        "    classes_prob=[]\n",
        "\n",
        "    for c in classes:\n",
        "        prob=classes[c]/data_len\n",
        "        classes_prob.append(prob)\n",
        "    print(classes_prob)\n",
        "    print(\"Entropy of classes in Mushroom: \", H(classes_prob))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "v6wx9eJtBeNh",
      "metadata": {
        "id": "v6wx9eJtBeNh"
      },
      "outputs": [],
      "source": [
        "# You many change to the location of mushrooms.csv on your computer\n",
        "DATAFILE = '../data/mushrooms.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "527aaa63",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "527aaa63",
        "outputId": "7d8584d1-df86-429e-982a-ded9a51bac3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Length:  8124\n",
            "{1: 3916, 0: 4208}\n",
            "[0.48202855736090594, 0.517971442639094]\n",
            "Entropy of classes in Mushroom:  0.9990678968724604\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(DATAFILE)\n",
        "\n",
        "labelencoder=LabelEncoder()\n",
        "\n",
        "for column in df.columns:\n",
        "    df[column]=labelencoder.fit_transform(df[column])\n",
        "\n",
        "# After replacing categories of features by ordinal values\n",
        "# print(\"After replacing categories of features by ordinal values\")\n",
        "# print(df.head)\n",
        "# Calculating entropy for classes\n",
        "\n",
        "calculate_class_entropy(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ba55f91",
      "metadata": {
        "id": "3ba55f91"
      },
      "source": [
        "### Computing the entropy of a feature value\n",
        "\n",
        "* Write a function that will compute the entropy of a feature value.\n",
        "* A feature may contain one of several values. For example feature \"cap-shape\" may contain of the following five values:\n",
        "    - bell=b\n",
        "    - conical=c \n",
        "    - convex=x\n",
        "    - flat=f \n",
        "    - knobbed=k\n",
        "    - sunken=s\n",
        "* Each of the above values belong to one of the classes.\n",
        "* Write a function to calculate entropy of each value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cecea8ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cecea8ea",
        "outputId": "d6969453-2c64-4eae-ea3c-0ff0f55bbd92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature name:  cap-shape\n",
            "{5: {'count': 3656, 'classes': {1: 1708, 0: 1948}}, 0: {'count': 452, 'classes': {0: 404, 1: 48}}, 4: {'count': 32, 'classes': {0: 32}}, 2: {'count': 3152, 'classes': {0: 1596, 1: 1556}}, 3: {'count': 828, 'classes': {0: 228, 1: 600}}, 1: {'count': 4, 'classes': {1: 4}}}\n"
          ]
        }
      ],
      "source": [
        "def calculate_feature_entropy(data, feature):\n",
        "    feature_values = {} #Here we will store frequencies of feature values \n",
        "    #Iterate the dataset to get each data poin\n",
        "    #print(data.iloc[0])\n",
        "\n",
        "    for index, data_point in data.iterrows():\n",
        "        #print(data_point['class'], data_point[feature])\n",
        "        #break\n",
        "        ft  = data_point[feature]\n",
        "        cls = data_point['class']\n",
        "\n",
        "        if ft in feature_values:\n",
        "            feature_values[ft]['count']+=1\n",
        "\n",
        "            if cls in feature_values[ft]['classes']:\n",
        "                feature_values[ft]['classes'][cls]+=1\n",
        "            else:\n",
        "                feature_values[ft]['classes'][cls]=1\n",
        "        else:\n",
        "            feature_values[ft]={}\n",
        "            feature_values[ft]['count']=1\n",
        "            feature_values[ft]['classes']={}\n",
        "            feature_values[ft]['classes'][cls]=1\n",
        "        \n",
        "        \n",
        "    print(\"Feature name: \", feature)\n",
        "    print(feature_values)\n",
        "\n",
        "    #for feature_value, feature_stats in feature_values.items():\n",
        "    #    prob=[]\n",
        "    #    print(H(prob))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2t_zRpf00Y7I",
      "metadata": {
        "id": "2t_zRpf00Y7I"
      },
      "outputs": [],
      "source": [
        "FEATURE='cap-shape'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faac3b0c",
      "metadata": {
        "id": "faac3b0c"
      },
      "outputs": [],
      "source": [
        "calculate_feature_entropy(df, FEATURE)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
